

####################################################################

Workflow Description Language: A "configuration" for the engine to behave 


workflow:
 zip:
  inputs:
   infile:
     type : file
     name : foodselfie.dat
     location: /source
   compression-ratio:
     type : int
     value : 50
   outputs:
    outfile:
     type : file
     name : foodselfie.zip
     location: /dest 
	        

####################################################################

"Convention over Configuration"


Things should be as easy as:


workflow:
 zip:
    
    
Note:

1.  The "zip" step assumes certain convetion for input file and output file.
    Example: A local foodselfie.dat is compressed into foodselfie.zip
    
    
    Perfect for repetitve job execution as long as we conform to the "conventions"


####################################################################

Let us look at a configuration system that helps us to embed convetions 

workflow:
	convert-doc:
	    inputs:
	        inparam:
	            type: file
	            location: /path/to/report.pages
	    outputs:
	        outparam:
	            type: file
	            location: /path/to/report.doc
	zip:
	    input:
	        inparam:
	            type: file
	            location: /path/to/report.doc
	    outputs:
	        outparam:
	            type: file
	            location: /path/to/report.zip


Verbose?

####################################################################

Lets utilise two things here:


1. Knowledge of type information of "inparam" as defined by "convert-doc"
2. Convention of when we are trying to specifying metadata about a file, if only a string is avialable that is path. 


workflow:
	convert-doc:
	    inputs:
	        inparam: /path/to/report.pages
	    outputs:
	        outparam: /path/to/report.doc
	zip:
	    inputs:
	        inparam: /path/to/report.doc
	    outputs:
	        outparam: /path/to/report.zip

####################################################################

But how do we let know Zip to depend on output produced by convert-doc

workflow:
	convert-doc:
	    inputs:
	        inparam: /path/to/report.pages
	    outputs:
	        outparam: /path/to/report.doc
	zip:
	    inputs:
	        inparam: convert-doc/outparam
	    outputs:
	        outparam: /path/to/report.zip

Technicality:

1. Decided convention of path string
2. Provided a mapping/linking

Well, lets modify the convention as:

a. Treat it as mapping. If found substitue and use
b. If no such mapping found treat it as path string (if file)


####################################################################


Some examples of how to deal with basic types and file collection etc 

workflow:
	sort:
	    inputs:
	        unsorted:
	            type : array
	            elements : integer
	            value : [ 55, 1, 6, 2 ]
	    outputs:
	        sorted-list:
	            type : array
	            elements : integer
	serialise:
	    inputs:
	        data : sort/sorted-list;
	    outputs:
	        saved-file: /home/list.txt
	        

Using type information we can minimize it to

workflow:
	sort:
	    inputs:
	        unsorted: [ 55, 1, 6, 2 ]
	serialise:
	    inputs:
	        data : sort/sorted-list;
	    outputs:
	        saved-file: /home/list.txt



Now lets introduce another convention,

1. If a step produces an output named "X" and there are steps that accepts input named "X" then we implicitly link them.

For the example above, lets say the output of sort is named "data" then it reduces to


workflow:
	sort:
	    inputs:
	        unsorted: [ 55, 1, 6, 2 ]
	serialise:
	    outputs:
	        saved-file: /home/list.txt

Note, In the case of where the world is simple and there is only one input and output, we can simplify further
 
workflow:
	sort: 
	    input: [ 55, 1, 6, 2 ]
	serialise: 
	    output: /home/list.txt

   
Compare this to the verbose definition above.


####################################################################

But world is not simple. It's about multiple inputs outputs and collection of files etc.


workflow:
	zip:
	    inputs:
	        files-to-zip:
	            type : array
	            element : file
	            value : [ a.txt, b.txt, c.txt, d.txt ]
	    output: /path/to/mydata.zip


Can become,

workflow:
	zip:
	    input:[ a.txt, b.txt, c.txt, d.txt ]
	    output: /path/to/mydata.zip
    move:
        output: /destination/path/mydata.zip

Here, assume implicit lining using "name" matching.


####################################################################

File(s) by pattern matching / filter


workflow:
	mashup:
	    inputs:
	        aset:
	            type: array
	            element : file
	            location : ../files
	            pattern : 
	             - a?b.tx
	             - cc[acd]?c.q
	        anotherset:
	            type : array
	            element : file
	            pattern : 
	                - location : path1
	                  value : a?b.txt
	                - location" : path1
	                  value : cc*.q
	    output: /destination/path/mashup.data
	
	archive:
	    input: mashup/output
	    output: /new/path/mashup.tar
	    
	    
Using type information and convention of using local directory as default path, we can reduce it to,

workflow:
	mashup:
	    inputs:
	        aset:
	            pattern : 
	             - a?b.tx
	             - cc[acd]?c.q
	        anotherset:
	            pattern : 
	                - location : path1
	                  value : a?b.txt
	                - location" : path1
	                  value : cc*.q
	    output: /destination/path/mashup.data
	archive:
	    input: mashup/output
	    output: /new/path/mashup.tar	        

####################################################################

Sidecar files

workflow:
	maleria:
	    inputs:
	        read_files_1:
	            type : array
	            element : file
	            location : ../data/S1_R1.fastq.gz
	            sidecar : 
	                -   ab.txt
	                -   cc.q
	        read_files_2:
	            type : array
	            element : file
	            location : ../data/S1_R1.fastq.gz
	            sidecar :
	                -   location : path
	                    pattern : a?b.txt
	                    
	                -   location : path
	                    pattern : XX?.txt


####################################################################


Inputs defined int separate YAML


workflow:
	find-variant:
	    input:
	        child_read_1 :
	        child_read_2 :
	        
	        

YAML:


child_read_1:
    type : array
    element : file
    location : ../data/S1_R1.fastq.gz
    sidecar : 
        -   ab.txt
        -   cc.q



####################################################################


Lets see if we can make some sensible examples,



workflow:

    child_read_1 : 
        type : file
        location: ../data/
        pattern: "S1_R1.fastq.gz"
        format: "edam:format_1930"

    child_read_2 : 
        type : file
        location: ../data/
        pattern: "S2_R1.fastq.gz"
        format: "edam:format_1930"
    
    
    # Quality inspection of raw data:
    fastqc:
        inputs:
            fastq: [ child_read_1, child_read_2 ]
            outdir: "."
        #implicit outputs: zippedfile and report
            
    # Alignment to ref v29 with bowtie2
    align:
        tool : bowtie2
        inputs:
            one : child_read_1
            two : child_read_2
            sensitive-local: true
            samout: "alignment.sam"
            threads: 8
            
        #Implicit output aligned-file
        
    #convert to bam
    convert:
        tool: samtools-view
        inputs:
            input: align/aligned-file
            output-name : "alignment.bam"
            threads: 8
    
         #Implicit output "output"
    #sort and compressed
    sort:
        tool: samtools-sort
        inputs: convert/output
        
        
################################################################################

But real life is not that simple.

we want set of files to be processed in parallel, join, parallel etc.
files are associated sets. Their names are in pattern.



 workflow:

    child_read_1 : 
        type : file[]
        location: ../data/
        pattern: "S?_R1.fastq.gz"

    child_read_2 : 
        type : file[]
        location: ../data/
        pattern: "S?_R2.fastq.gz"
        
    parent_read_1 : 
        type : file[]
        location: ../data/
        pattern: "P?_R1.fastq.gz"

    parent_read_2 : 
        type : file[]
        location: ../data/
        pattern: "S?_R2.fastq.gz"

    alignment:
        type: file
        location: /path/to/3D7-merge-B3_S1-C5_S2.bam

    gff:
        type: file
        location: /path/to/PlasmoDB-29_Pfalciparum3D7.gff        

    blacklist:
        type: file
        location: /path/to/CentromereTelomereRegions.bed

    reference:
        type: file
        location: /path/to/PlasmoDB-29_Pfalciparum3D7_Genome.fasta
        sidecar:
            - PlasmoDB-29_Pfalciparum3D7_Genome.fasta.amb
            - PlasmoDB-29_Pfalciparum3D7_Genome.fasta.ann
            - PlasmoDB-29_Pfalciparum3D7_Genome.fasta.bwt
            - PlasmoDB-29_Pfalciparum3D7_Genome.fasta.fai
            - PlasmoDB-29_Pfalciparum3D7_Genome.fasta.pac
            - PlasmoDB-29_Pfalciparum3D7_Genome.fasta.sa
        
    # Quality inspection of raw data
    fastqc:
        cwl-tool: fastqc
        inputs:
            fastq: child_read_1 + child_read_2 + parent_read_1 + parent_read_2
            outdir: "."
        outputs:
            zippedFile:  #<------------- Implicit mapping to CWL tool outputs
            report:


    #child pipeline
    scatter:
        use: [ child_read_1, child_read_2 ]
        method: dotproduct
        provide: [ one, two ]
        
        # Alignment to ref v29 with bowtie2
        align:
            cwl-tool: bowtie2
            inputs:
                #implicit input one by scatter
                #implicit input two by scatter
                samout:
                    type: string
                    value : $(one.basename) + ".sam"
                threads:
                    type : int
                    value : 8
                 sensitive-local:
                    type : boolean
                    value: true
                 bt2-idx:
                    type : string
                    value : $(reference.indexname)
            outputs:
                aligned-file:
        
        # convert to bam
        convert:
            cwl-tool: samtools-view
            inputs:
                input: aligned/aligned-file
                output-name:
                    type: string
                    value: $(one.basename) + ".bam"
                threads:
                    type : int
                    value : 8
            outputs:
                output:
        
        # sort and compress
        sort:
            cwl-tool: samtools-sort
            inputs:
                input: convert/output
                output-name:
                    type: string
                    value: $(one.basename) + ".sorted.bam"
                threads:
                    type : int
                    value : 8
            outputs:
                sorted:
        
        # index bam    
        index:
            cwl-tool: samtools-index
            inputs:
                input: sort/sorted
            #implicit output
        
        # Remove duplicate reads
        dedup:
            cwl-tool: picar-markduplicates
            inputs:
                inputFileName_markDups: sort/sorted
                outputFileName_markDups:
                    type: string
                    value: $(one.basename) + "_nodup.bam"
                 metricsFile:
                    type: string
                    value: $(one.basename) + "_duplic.metrics"
                removeDuplicates: true
            outputs:
                markDups_output:
                markDups_metrics:
        
        # index duplicates
        index-dedup:
            cwl-tool: samtools-index
            inoputs:
                input: dedup/markDups_output
            outputs:
                index:
        
        # Collect insert-size, aka fragment-size, statistics
        insert-metrics:
            cwl-tool: picard-CollectInsertSizeMetrics
            inputs:
                input: dedup/markDups_output
                output:
                    type: string
                    value: $(one.basename) + ".insert-metrics.txt"
                histogram_file:
                    type: string
                    value: $(one.basename) + ".insert-metrics.pdf"
                removeDuplicates: true
            outputs:
                output:
                histogram:
        
        # Inspect coverage and gene bias:-
        # bedtools genomecov -d -split -ibam 225-${fn}_nodup.bam
        coverage:
            cwl-tool: bedtools-genomecov
            inputs:
                input:
                    source: dedup/markDups_output
                    value: 
                        ${
                          self.format = "http://edamontology.org/format_2572";
                          return self;
                        }
                depth:
                    type : 'enum'
                    value: '-d' #enum value form input specification of the CWL tool
                
                genomecoverageout:
                    type: string
                    value: $(one.basename) + ".genomecov.out"
                
                split: true
                
            outputs:
                genomecoverage:
         
         # Summarize genomecov output
         summarize-genomecov:
            cwl-tool: awk
            inputs:
                infile: coverage/genomecoverage
                program:
                    type: string
                    value: $( '{total += $3; count +=1; sumsq += $3*$3}; END {print "mean cov is", total / count, ". Var of cov is", (sumsq - total^2/count)/(count-1)}' ) 
                outputFileName:
                    type : string
                    value: $(one.basename) + ".genomecov.summary.txt"
            outputs:
                output:
        
        # bedtools intersect genic
        intersect-genic:
            cwl-tool: bedtools-intersect
            inputs:
                inputA:
                    source: dedup/markDups_output
                    value:
                        ${
                          self.format = "http://edamontology.org/format_2572";
                          return self;
                        }
                inputB: gff
                split: true
                intersectout:
                    type: string
                    value: $(one.basename) + ".intersect.nongenic.bam"
            outputs:
                intersect:
        
         # Inspect coverage of genic intersection
         coverage-genic:
            cwl-tool: bedtools-genomecov
            inputs:
                input:
                    source: intersect-genic/intersect
                    value:
                        ${
                            self.format = "http://edamontology.org/format_2572";
                            return self;
                        }
                genomecoverageout:
                    type : string
                    value: $(one.basename) + ".genic.genomecov.out"
                
                    
                depth:
                    type : 'enum'
                    value: '-d' #enum value form input specification of the CWL tool
                    
                split: true
                
            outputs:
                genomecoverage:
                
        
        # Summarize coverage output
        summarize-genic-genomecov:
            cwl-tool: awk
            inputs:
                inFile: coverage-genic/genomecoverage
                program:
                    type: string
                    value: $( '{total += $3; count +=1}; END {print "total of all reads at genic bases", total, ", mean cov is", total / 13979861}' )
                
                outputFileName:
                    type : string
                    value: $(one.basename) + ".genic.genomecov.summary.txt"
            outputs:
                output:
                
        # Looking at bams in IGV is memory-hungry, and could be replaced by using tdf-format
        # coverage files. 3D7-merge-B3_S1-C5_S2.bam done at command line.
        # Default window size is 25bp
        
        igvtools:
            cwl-tool: igvtools-count
            
            inputs:
                inputFile: dedup/markDups_output
                outputFileName:
                    type : string
                    value: $(one.basename) + ".tdf"
                gnome: reference
                
            outputs:
                output:
                
                    
    #######       
    process:
        repeat:
            for: 
                iter1: [ child_read_1, child_read_2]
                iter2: [ parent_read_1, parent_read_2 ]
            mapto: [ read1, read2 ]
            do:
                scatter:
                    use: [ read_1, read_2 ]
                    method: dotproduct
                    provide: [ one, two ]
                    
                    # Alignment to ref v29 with bowtie2
                    align:
                        cwl-tool: bowtie2
                        inputs:
                            #implicit input one by scatter
                            #implicit input two by scatter
                            samout:
                                type: string
                                value : $(one.basename) + ".sam"
                            threads:
                                type : int
                                value : 8
                             sensitive-local:
                                type : boolean
                                value: true
                             bt2-idx:
                                type : string
                                value : $(reference.indexname)
                        outputs:
                            aligned-file:
        
                    # convert to bam
                    convert:
                        cwl-tool: samtools-view
                        inputs:
                            input: aligned/aligned-file
                            output-name:
                                type: string
                                value: $(one.basename) + ".bam"
                            threads:
                                type : int
                                value : 8
                        outputs:
                            output:
        
                    # sort and compress
                    sort:
                        cwl-tool: samtools-sort
                        inputs:
                            input: convert/output
                            output-name:
                                type: string
                                value: $(one.basename) + ".sorted.bam"
                            threads:
                                type : int
                                value : 8
                        outputs:
                            sorted:
        
                    # index bam    
                    index:
                        cwl-tool: samtools-index
                        inputs:
                            input: sort/sorted
                        #implicit output
        
                    # Remove duplicate reads
                    dedup:
                        cwl-tool: picar-markduplicates
                        inputs:
                            inputFileName_markDups: sort/sorted
                            outputFileName_markDups:
                                type: string
                                value: $(one.basename) + "_nodup.bam"
                             metricsFile:
                                type: string
                                value: $(one.basename) + "_duplic.metrics"
                            removeDuplicates: true
                        outputs:
                            markDups_output:
                            markDups_metrics:
        
                    # index duplicates
                    index-dedup:
                        cwl-tool: samtools-index
                        inoputs:
                            input: dedup/markDups_output
                        outputs:
                            index:
        
                    # Collect insert-size, aka fragment-size, statistics
                    insert-metrics:
                        cwl-tool: picard-CollectInsertSizeMetrics
                        inputs:
                            input: dedup/markDups_output
                            output:
                                type: string
                                value: $(one.basename) + ".insert-metrics.txt"
                            histogram_file:
                                type: string
                                value: $(one.basename) + ".insert-metrics.pdf"
                            removeDuplicates: true
                        outputs:
                            output:
                            histogram:
        
                    # Inspect coverage and gene bias:-
                    # bedtools genomecov -d -split -ibam 225-${fn}_nodup.bam
                    coverage:
                        cwl-tool: bedtools-genomecov
                        inputs:
                            input:
                                source: dedup/markDups_output
                                value: 
                                    ${
                                      self.format = "http://edamontology.org/format_2572";
                                      return self;
                                    }
                            depth:
                                type : 'enum'
                                value: '-d' #enum value form input specification of the CWL tool
                
                            genomecoverageout:
                                type: string
                                value: $(one.basename) + ".genomecov.out"
                
                            split: true
                
                        outputs:
                            genomecoverage:
         
                     # Summarize genomecov output
                     summarize-genomecov:
                        cwl-tool: awk
                        inputs:
                            infile: coverage/genomecoverage
                            program:
                                type: string
                                value: $( '{total += $3; count +=1; sumsq += $3*$3}; END {print "mean cov is", total / count, ". Var of cov is", (sumsq - total^2/count)/(count-1)}' ) 
                            outputFileName:
                                type : string
                                value: $(one.basename) + ".genomecov.summary.txt"
                        outputs:
                            output:
        
                    # bedtools intersect genic
                    intersect-genic:
                        cwl-tool: bedtools-intersect
                        inputs:
                            inputA:
                                source: dedup/markDups_output
                                value:
                                    ${
                                      self.format = "http://edamontology.org/format_2572";
                                      return self;
                                    }
                            inputB: gff
                            split: true
                            intersectout:
                                type: string
                                value: $(one.basename) + ".intersect.nongenic.bam"
                        outputs:
                            intersect:
        
                     # Inspect coverage of genic intersection
                     coverage-genic:
                        cwl-tool: bedtools-genomecov
                        inputs:
                            input:
                                source: intersect-genic/intersect
                                value:
                                    ${
                                        self.format = "http://edamontology.org/format_2572";
                                        return self;
                                    }
                            genomecoverageout:
                                type : string
                                value: $(one.basename) + ".genic.genomecov.out"
                
                    
                            depth:
                                type : 'enum'
                                value: '-d' #enum value form input specification of the CWL tool
                    
                            split: true
                
                        outputs:
                            genomecoverage:
                
        
                    # Summarize coverage output
                    summarize-genic-genomecov:
                        cwl-tool: awk
                        inputs:
                            inFile: coverage-genic/genomecoverage
                            program:
                                type: string
                                value: $( '{total += $3; count +=1}; END {print "total of all reads at genic bases", total, ", mean cov is", total / 13979861}' )
                
                            outputFileName:
                                type : string
                                value: $(one.basename) + ".genic.genomecov.summary.txt"
                        outputs:
                            output:
                
                    # Looking at bams in IGV is memory-hungry, and could be replaced by using tdf-format
                    # coverage files. 3D7-merge-B3_S1-C5_S2.bam done at command line.
                    # Default window size is 25bp
        
                    igvtools:
                        cwl-tool: igvtools-count
            
                        inputs:
                            inputFile: dedup/markDups_output
                            outputFileName:
                                type : string
                                value: $(one.basename) + ".tdf"
                            gnome: reference
                
                        outputs:
                            output:
    
    
    # Parent Merge
    merge-parents:
        cwl-tool: samtools-merge
        inputs:
            input: process[iter2]/dedup/markDups_output
            outputFile:
                value: $('3D7-merge-B2_S1-F4_S4.bam')
        outputs:
            merge:

    # GRIDSS
    scatter:
        use: [ process[iter2]/dedup/markDups_output ]
        provide: [ main-input ]
            
        gridss:
            cwl-tool: gridss-callvariants
            inputs:
                input:
                    source: main-input
                    value:
                        ${
                            if ( self == null ) {
                                return null;
                            } else {
                                return [self];
                            }
                        }
                input2:
                    source: merge-parents/merge
                    value:
                        ${
                            if ( self == null ) {
                                return null;
                            } else {
                                return [self];
                            }
                        }
                
                input-label:
                    type : array
                    element : string
                    source : main-input
                    value: 
                        ${
                            return [self.nameroot];
                        }
                input-label2:
                    type : array
                    element : string
                    source : merge-parents/merge
                    value: 
                        ${
                            return [self.nameroot];
                        }
                output:
                    source: main-input
                    value:
                        ${
                            return self.nameroot + '.gridss.assembly.vcf'
                        }
                assembly:
                    source: main-input
                    value:
                        ${
                            return self.nameroot + '.gridss.assembly.bam'
                        }
                reference_sequence: reference
                blacklist: blacklist
                
            
            
                #Implicit maininput
                parent-merge: merge-parents/merge
                #Implicit reference
                #Implicit blacklist
                
            outputs:
                vcf:
                bam:
                vcf_working:
                bam_working:
                
            

####################################################################
####################################################################
####################################################################





workflow:
    outputLocation: "."
    reference_genome: pf123
    
    child_reads : 
        type : paired_reads
        location: ../data/
        pattern: "S1_R?.fastq.gz"

    parent_reads : 
        type : paired_reads
        location: ../data/
        pattern: "S2_R?.fastq.gz"
        
    # Quality inspection of raw data:
    fastqc:            
            
    # Alignment to ref v29 with bowtie2
    align:
            
 
But the world is not ideal, we always have certain changes.
Domain specific worlflows can hugely benefit from usage of "convention"


workflow:
	find-variant:
	    inputs:
	        -   child_reads_1 : read
	        -   child_reads_2 : read
	        -   parent_reads_1 : read
	        -   parent_reads_2 : read
	        -   3D7-merge-B3_S1-C5_S2 : alignment
	        -   PlasmoDB-29_Pfalciparum3D7_Genome : reference
	        -   PlasmoDB-29_Pfalciparum3D7 : gff
	        -   CentromereTelomereRegions : backlist
	        
 
#This is where my primitive SE mind just treats them as some kind of binar data



Now: Lets look at some configuration mechanism that will lead us to use convention 


####################################################################

workflow:
	find-variant:
	    inputs:
	        -   "child_reads_1" :
	            type "read"
	        -   "child_reads_2" : "read"
	        -   "parent_reads_1" : "read"
	        -   "parent_reads_2" : "read"
	        -   "3D7-merge-B3_S1-C5_S2" : "alignment"
	        -   "PlasmoDB-29_Pfalciparum3D7_Genome" : "reference"
	        -   "PlasmoDB-29_Pfalciparum3D7" : "gff"
	        -   "CentromereTelomereRegions" : "backlist"
